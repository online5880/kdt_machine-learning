{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-1mU476v18_"
   },
   "source": [
    "# 기계학습 모델 최적화를 위한 GridSearch, RandomSearch Cross Validation 알아보기\n",
    "---\n",
    "파이썬(Python)으로 기계학습을 구현할 때 고려해야 할 사항은 아주 많습니다. 이번에는 GridSearch, RandomSearch Cross Validation를 이용해서 기계학습 모델을 최적화하는 작업을 GridSearch, RandomSearch Cross Validation을 이용해서 알아보도록 하겠습니다. 두 교차검증 역시 사이킷런에서 `sklearn.model_selection` 모듈에서 지원하고 있습니다.\n",
    "</p></br></br>\n",
    "\n",
    "## 최적화(Optimization)\n",
    "---\n",
    "기계학습 모델을 만들 때는, 모델 종류 및 입력 데이터만 선정하는게 아니라 초매개변수(하이퍼파라미터, Hyper-parameter)를 설정하는 작업이 필요하며, 이를 최적화라고 합니다. 하이퍼파라미터란, 학습용으로 이용되지 않는 매개변수입니다. 이 값이 달라지면 모델의 특성에 차이가 생기기 때문에, 하이퍼파라미터 튜닝이라고 하는 모델 세부 조정 작업이 필요하지요. 그런데, 이 값을 어떻게 바꿔야 할지 모를 때 GridSearch, RandomSearch Cross Validation 등이 고려됩니다.\n",
    "</p></br></br>\n",
    "\n",
    "### GridSearch Cross Validation\n",
    "---\n",
    "GridSearch Cross Validation은 가능한 모든 하이퍼파라미터의 조합 중 최적의 조합을 선택하는 방식입니다. 해당 방법의 특성상, 가능한 모든 조합을 테스트해 보기 때문에 항상 최적의 결과를 찾을 수 있다는 장점이 있습니다. 다만, 시간과 컴퓨팅 파워가 많이 소모된다는 점이 큰 단점으로 다가오기 때문에 하이퍼파라미터의 조합을 일부분만 확인해 보는 방식으로 최적화를 진행하는 경우도 많습니다. 사이킷런(scikit-learn)에서는 `sklearn.model_selection.GridSearchCV`로 구현할 수 있으니, 아래 코드를 참조해 의사결정나무 분류기(Decision Tree Classifier) 모델의 최적화를 진행해 보도록 하겠습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1700464053154,
     "user": {
      "displayName": "박나연",
      "userId": "15219795176792784727"
     },
     "user_tz": -540
    },
    "id": "Bp2pUO-mv19C"
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# input data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.2, random_state=12345)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# hyperparameter\n",
    "parameters = {'max_depth': range(1,5), 'min_samples_split': range(2,5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "이번에 사용할 의사결정나무 모델은 `max_depth`가 1\\~4까지의 범위, `min_samples_split`이 2\\~4까지의 범위를 입력받을 수 있도록 Grid Search 설정을 진행해 봤습니다. Grid Search에 사용할 하이퍼파라미터는 딕셔너리 형태로 설정을 해 주는데요, 하이퍼파라미터의 이름을 key, 가능한 범위를 value 값으로 저장하면 됩니다.\n",
    "</br>\n",
    "다음으로는, 3-fold CV를 이용해서 Grid Search 결과를 표현하는 작업입니다. GridSearch Cross Validation 결과는 `cv_results_`딕셔너리에 저장되며, 이를 조회해서 최적의 하이퍼파라미터 조합을 알아볼 수 있습니다. 만약 가장 정확도가 높게 나오는 조합을 자동으로 확정하고 싶다면, GridSearchCV를 실행할 때 `refit=True` 매개변수를 입력해 주도록 합시다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1700464193722,
     "user": {
      "displayName": "박나연",
      "userId": "15219795176792784727"
     },
     "user_tz": -540
    },
    "id": "CzD4B3VVv19C",
    "outputId": "d1505d57-62be-4335-e978-279c0b3fe291"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 4}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 4}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 4}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  \\\n",
       "0   {'max_depth': 1, 'min_samples_split': 2}         0.683333   \n",
       "1   {'max_depth': 1, 'min_samples_split': 3}         0.683333   \n",
       "2   {'max_depth': 1, 'min_samples_split': 4}         0.683333   \n",
       "3   {'max_depth': 2, 'min_samples_split': 2}         0.958333   \n",
       "4   {'max_depth': 2, 'min_samples_split': 3}         0.958333   \n",
       "5   {'max_depth': 2, 'min_samples_split': 4}         0.958333   \n",
       "6   {'max_depth': 3, 'min_samples_split': 2}         0.966667   \n",
       "7   {'max_depth': 3, 'min_samples_split': 3}         0.966667   \n",
       "8   {'max_depth': 3, 'min_samples_split': 4}         0.966667   \n",
       "9   {'max_depth': 4, 'min_samples_split': 2}         0.966667   \n",
       "10  {'max_depth': 4, 'min_samples_split': 3}         0.966667   \n",
       "11  {'max_depth': 4, 'min_samples_split': 4}         0.966667   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0                10                0.7              0.675              0.675  \n",
       "1                10                0.7              0.675              0.675  \n",
       "2                10                0.7              0.675              0.675  \n",
       "3                 7                1.0              0.950              0.925  \n",
       "4                 7                1.0              0.950              0.925  \n",
       "5                 7                1.0              0.950              0.925  \n",
       "6                 1                1.0              0.950              0.950  \n",
       "7                 1                1.0              0.950              0.950  \n",
       "8                 1                1.0              0.950              0.950  \n",
       "9                 1                1.0              0.950              0.950  \n",
       "10                1                1.0              0.950              0.950  \n",
       "11                1                1.0              0.950              0.950  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch Cross Validation\n",
    "grid_dt = GridSearchCV(dt_clf, param_grid=parameters, cv=3, refit=True, return_train_score=True)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV result\n",
    "scores_df = pd.DataFrame(grid_dt.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1700464277880,
     "user": {
      "displayName": "박나연",
      "userId": "15219795176792784727"
     },
     "user_tz": -540
    },
    "id": "ME8nBUfQv19C",
    "outputId": "22ccb1b5-39f1-4cad-fadf-2892d0699bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'max_depth': 3, 'min_samples_split': 2}\n",
      "best score 96.67%\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print(f'best params:', grid_dt.best_params_)\n",
    "print(f'best score {grid_dt.best_score_:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsuDAWbj8bPz"
   },
   "source": [
    "</p></br></br>\n",
    "\n",
    "### RandomSearch Cross Validation\n",
    "---\n",
    "GridSearch Cross Validation이 이론적으로 최적의 하이퍼파라미터 조합을 찾을 수 있는 방법이지만, 이 방법은 모든 조합을 알아본다는 특성상 시간과 컴퓨팅 파워의 소모가 심하다는 단점이 있습니다. 이 때문에, 무작위 하이퍼파라미터의 조합을 이용해서 최적의 조합을 찾는 Random Search 방식을 이용하는 경우도 있는데요, 이는 무작위성에 의존하기 때문에 최적의 조합을 찾아낼 수 없는 경우도 있지만, 경우에 따라서 최소한의 시간과 컴퓨팅 파워의 투자로 만족스러운 결과를 얻어낼 수도 있습니다.\n",
    "</br>\n",
    "사이킷런(scikit-learn)에서는 `sklearn.model_selection.RandomizedSearchCV`로 해당 기능을 구현할 수 있습니다. 아래 코드를 참조해 GridSearchCV로 구현했던 의사결정나무 분류기 모델의 최적화 작업을 RandomizedSearchCV로 진행해 보도록 하겠습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1700464580934,
     "user": {
      "displayName": "박나연",
      "userId": "15219795176792784727"
     },
     "user_tz": -540
    },
    "id": "VmjI4ycL9CHd",
    "outputId": "8d3e6b9b-3edb-414a-8470-fbb9002a144c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'min_samples_split': 4, 'max_depth': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 1}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'min_samples_split': 3, 'max_depth': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'min_samples_split': 4, 'max_depth': 4}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'min_samples_split': 3, 'max_depth': 4}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'min_samples_split': 2, 'max_depth': 4}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'min_samples_split': 3, 'max_depth': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'min_samples_split': 3, 'max_depth': 1}</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'min_samples_split': 4, 'max_depth': 3}         0.966667                1   \n",
       "1  {'min_samples_split': 2, 'max_depth': 1}         0.683333                9   \n",
       "2  {'min_samples_split': 2, 'max_depth': 2}         0.958333                7   \n",
       "3  {'min_samples_split': 3, 'max_depth': 3}         0.966667                1   \n",
       "4  {'min_samples_split': 4, 'max_depth': 4}         0.966667                1   \n",
       "5  {'min_samples_split': 3, 'max_depth': 4}         0.966667                1   \n",
       "6  {'min_samples_split': 2, 'max_depth': 3}         0.966667                1   \n",
       "7  {'min_samples_split': 2, 'max_depth': 4}         0.966667                1   \n",
       "8  {'min_samples_split': 3, 'max_depth': 2}         0.958333                7   \n",
       "9  {'min_samples_split': 3, 'max_depth': 1}         0.683333                9   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0                1.0              0.950              0.950  \n",
       "1                0.7              0.675              0.675  \n",
       "2                1.0              0.950              0.925  \n",
       "3                1.0              0.950              0.950  \n",
       "4                1.0              0.950              0.950  \n",
       "5                1.0              0.950              0.950  \n",
       "6                1.0              0.950              0.950  \n",
       "7                1.0              0.950              0.950  \n",
       "8                1.0              0.950              0.925  \n",
       "9                0.7              0.675              0.675  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import package\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_dt = RandomizedSearchCV(estimator=dt_clf, param_distributions=parameters, n_iter=10,\n",
    "                               cv=3, random_state=12345, n_jobs=-1)\n",
    "random_dt.fit(X_train,y_train)\n",
    "\n",
    "# RandomizedSearchCV result\n",
    "scores_df = pd.DataFrame(random_dt.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'min_samples_split': 4, 'max_depth': 3}\n",
      "best score 96.67%\n"
     ]
    }
   ],
   "source": [
    "# best params\n",
    "print(f'best params:', random_dt.best_params_)\n",
    "print(f'best score {random_dt.best_score_:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# n_iter = 몇번이나 할꺼냐\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# n_jobs = cpu 사용 (-1은 전부 사용)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m random_dt \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mdt_clf, param_distributions\u001b[38;5;241m=\u001b[39mparameters, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12345\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m random_dt\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# RandomizedSearchCV result\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# n_iter = 몇번이나 할꺼냐\n",
    "# n_jobs = cpu 사용 (-1은 전부 사용)\n",
    "random_dt = RandomizedSearchCV(estimator=dt_clf, param_distributions=parameters, n_iter=10,\n",
    "                               cv=3, random_state=12345, n_jobs=-1)\n",
    "random_dt.fit(X_train,y_train)\n",
    "\n",
    "# RandomizedSearchCV result\n",
    "scores_df = pd.DataFrame(random_dt.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
